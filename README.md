# üöï Desafio T√©cnico: Engenharia de Dados NYC Taxi Trips

Este reposit√≥rio cont√©m uma solu√ß√£o completa de Engenharia de Dados **Serverless** para ingest√£o, processamento e **an√°lise pr√©-agregada** dos dados de viagens de t√°xi de Nova York.

A arquitetura utiliza uma stack **Cloud-Native (AWS)** com orquestra√ß√£o centralizada no **AWS Step Functions**, garantindo um fluxo ELT robusto: **Landing** $\rightarrow$ **Consumer** $\rightarrow$ **Reporting**.

-----

## üöÄ Stack Tecnol√≥gica e Arquitetura Final

| Etapa do Pipeline | Tecnologia/Servi√ßo | Finalidade no Projeto |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | **AWS Step Functions** | **Controlador Serverless.** Gerencia o *workflow* completo e √© respons√°vel por orquestrar a **execu√ß√£o paralela (fan-out)** dos Jobs de Processamento por m√™s e tipo de viagem. |
| **Infraestrutura como C√≥digo (IaC)** | **Terraform** | Provisionamento seguro e automatizado de **todos** os recursos (S3, Glue Jobs, Lambda, Step Functions, IAM Roles e Tabelas do Athena). |
| **Data Lake e Armazenamento** | **Amazon S3 / Delta Lake** | Armazenamento persistente nas camadas: `landing`, `consumer` (Delta/Parquet) e `analytics/reporting` (Parquet pr√©-agregado). |
| **Ingest√£o (EL)** | **AWS Lambda (Python)** | Baixa os arquivos e faz o upload para a **Landing Zone**, particionado por *timestamp* de ingest√£o. |
| **Processing (T - Camada Consumer)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** L√™ a √∫ltima vers√£o dos dados, aplica Data Quality (DQ), unifica o *schema* e salva na **Camada Consumer** (Delta Lake). |
| **Reporting (T - Camada Reporting)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** Executa as agrega√ß√µes **Q1 e Q2** e salva os relat√≥rios na **Camada Reporting** (pronto para consumo). |
| **Cat√°logo de Dados** | **AWS Glue Data Catalog** | Registro do *schema* de todas as tabelas para acesso via SQL (Athena). |
| **Consumo e An√°lise Ad-Hoc** | **Amazon Athena / PyAthena** | Permite consultas SQL diretas e de baixo custo sobre os relat√≥rios pr√©-agregados. |

-----

## üí∞ FinOps: Gest√£o de Custos Serverless

A arquitetura **Serverless** (Lambda, Glue, Step Functions) oferece um excelente balan√ßo entre performance e custo, seguindo o princ√≠pio **pay-per-use**.

### Principais Drivers de Custo

  * **AWS Glue (DPUs):** Componente de maior custo potencial, baseado em **DPUs (Data Processing Units) por hora**. Mitigado por Glue 3.0 e otimiza√ß√£o do tempo de execu√ß√£o.
  * **Amazon S3 (Armazenamento):** Custo cont√≠nuo para manter os dados nas tr√™s camadas.

### Boas Pr√°ticas FinOps

* **Destrui√ß√£o Imediata:** Ap√≥s o teste e valida√ß√£o, utilize o comando `make destroy` para desprovisionar toda a infraestrutura e evitar cobran√ßas recorrentes.

-----

## üéØ Objetivo e Transforma√ß√£o

O objetivo √© processar os dados de viagens de t√°xi de **Janeiro a Maio de 2023** e disponibilizar, na **Camada Reporting**, as seguintes an√°lises prontas:

1.  **Q1:** M√©dia de valor total (`total_amount`) por m√™s.
2.  **Q2:** M√©dia de passageiros por cada hora do dia, agrupado por tipo de viagem.

-----

## 1\. ‚öôÔ∏è Setup, Deploy e Execu√ß√£o do ELT

### 1.1. Pr√©-requisitos e Setup Local

1.  **Python 3.x**, **`pip`**, **`make`** e **Terraform CLI**.
2.  **AWS CLI** configurado com credenciais de acesso apropriadas.
3.  **Configura√ß√£o do Bucket:** Antes de rodar o `make deploy`, edite o arquivo `infra/main.tf` e defina o nome desejado e √∫nico para o seu *bucket* S3 na vari√°vel `data_lake_bucket_name`.

### 1.2. Provisionamento da Infraestrutura (IaC)

Utilize o **`Makefile`** para automatizar o *build* e o deploy via Terraform.

| Comando | A√ß√£o Executada | Observa√ß√µes |
| :--- | :--- | :--- |
| **`make deploy`** | **Execu√ß√£o Completa.** Prepara o pacote Lambda e executa o `terraform apply --auto-approve`. | Comando principal de *setup* e deployment. |
| **`make destroy`** | **Destr√≥i toda a infraestrutura da AWS.** | **CUIDADO: Apaga dados no S3.** |
| **`make clean`** | Limpeza Local | Remove artefatos tempor√°rios e de cache. |

### 1.3. Execu√ß√£o da Orquestra√ß√£o (Pipeline Din√¢mico)

O Step Function aceita um *payload* JSON para definir a execu√ß√£o em lote por `months` e `trip_types`.

**Payload de Exemplo (Execu√ß√£o em Lote):**

```json
{
  "datalakeBucket": "nyc-taxi-data-lake-jha-case-ifood",
  "year": "2023",
  "months": ["02", "03", "04", "05"],
  "trip_types": ["yellow", "green"]
}
````

**Execu√ß√£o Customizada:**

```bash
# Obtenha o ARN da State Machine na sa√≠da do Terraform
STATE_MACHINE_ARN="ARN_DA_SUA_STATE_MACHINE" 

# Exemplo de invoca√ß√£o com payload customizado
INPUT='{"datalakeBucket": "nyc-taxi-data-lake-jha-case-ifood", "year": "2024", "months": ["07"], "trip_types": ["yellow"]}'

aws stepfunctions start-execution \
    --state-machine-arn $STATE_MACHINE_ARN \
    --name "Run-Custom-Batch-$(date +%Y%m%d%H%M%S)" \
    --input "$INPUT"
```

-----

## 2\. üß© Reporting e Consumo Final de Dados

Ap√≥s a conclus√£o do Job de Reporting, os relat√≥rios agregados est√£o dispon√≠veis na **Camada Reporting** do S3 (`/analytics/reporting/`) e catalogados pelo Glue Data Catalog.


### Tabelas do Glue Catalog para Consulta

| Tabela | An√°lise |
| :--- | :--- |
| `q1_monthly_revenue` | M√©dia Mensal de Receita |
| `q2_hourly_passengers` | M√©dia Hor√°ria de Passageiros |

### Acesso via Amazon Athena (SQL)

No Console do **Amazon Athena**, execute:

```sql
SELECT 
    report_month, 
    ROUND(avg_total_amount, 2) AS avg_revenue
FROM 
    "nyc_taxi_db"."q1_monthly_revenue"
ORDER BY 
    report_month;
```

### Acesso Program√°tico Local (Script PyAthena)

Instale as depend√™ncias locais e execute o script `analysis/analytics_job.py`:

```bash
# Instala o driver do Athena e o Pandas
pip3 install pyathena[pandas]

# O script ir√° consultar o Athena e imprimir os resultados
python analysis/analytics_job.py
```

-----

## 3\. üí° Melhorias e Pr√≥ximos Passos (To-Do)

A solu√ß√£o atual √© funcional, mas esta lista de melhorias visa aumentar a **resili√™ncia**, a **performance** e a **governan√ßa** do pipeline, abordando li√ß√µes aprendidas nos testes.

### 3.1. Resolu√ß√£o de Inconsist√™ncia de Schema (M√™s 1)

Oportunidade | Descri√ß√£o | Justificativa Arquitetural |
| :--- | :--- | :--- |
**Tratamento Robusto de Schema Drift (M√™s 1)** | Os testes indicaram falha no processamento dos dados do M√™s 1 (Janeiro), sugerindo uma **inconsist√™ncia de tipo de dado (schema drift)** n√£o tratada. A√ß√£o (To-Do): Implementar a defini√ß√£o de *schema* estrito para colunas cr√≠ticas e configurar o Spark para mover registros inv√°lidos para uma Dead Letter Queue (DLQ), isolando o problema e permitindo o processamento cont√≠nuo dos dados v√°lidos. | Corrige a falha de processamento observada no M√™s 1, garantindo que o pipeline seja tolerante a dados malformados e inconsist√™ncias de tipo. |

### 3.2. Melhorias de Resili√™ncia e Data Quality (DQ)

| Oportunidade | Descri√ß√£o | Justificativa Arquitetural |
| :--- | :--- | :--- |
| **Monitoramento Ativo de DQ** | Implementar uma biblioteca de DQ (como **GDQ** ou **Great Expectations**) no Job de Processing. Definir regras (ex: `total_amount` nunca deve ser negativo) e criar um **Alerta SNS/CloudWatch** se uma regra falhar. | Migra de uma checagem de DQ passiva (filtros) para um monitoramento ativo, alertando *antes* que dados ruins cheguem ao Reporting. |
| **Integra√ß√£o com AWS Lake Formation** | Aplicar pol√≠ticas de seguran√ßa e acesso granular baseadas em tags nas tabelas do Glue Catalog (ex: restringir o acesso a colunas sens√≠veis, se houvesse, como dados de motorista). | Garante um Data Lake seguro, controlando quem pode consultar as camadas Consumer e Reporting (Governan√ßa e Seguran√ßa). |
| **Data Lineage (Linhagem de Dados)** | Configurar o AWS Glue para registrar a linhagem de dados, ou usar o *logging* do Delta Lake (Audit History). | Essencial para *troubleshooting* e auditoria. Permite rastrear um valor do Reporting de volta √† Landing Zone. |

### 3.3. Melhorias na Experi√™ncia do Desenvolvedor (DX)

| Oportunidade | Descri√ß√£o | Justificativa Arquitetural |
| :--- | :--- | :--- |
| **Testes Unit√°rios/Integra√ß√£o** | Adicionar um *framework* de testes (ex: **Pytest**) para testar as fun√ß√µes PySpark de transforma√ß√£o (`apply_data_quality_and_transform`) localmente, antes do deploy no Glue. | Aumenta a confian√ßa no c√≥digo e reduz o ciclo de desenvolvimento/depura√ß√£o no ambiente de nuvem, que √© mais lento e caro. |
| **CI/CD Simplificado** | Integrar o pipeline Terraform/make deploy com um servi√ßo de CI/CD (ex: GitHub Actions ou AWS CodePipeline) para automatizar o deploy a cada *merge* na *branch* `main`. | Migra para um fluxo de trabalho DevOps completo, garantindo que a infraestrutura seja deployada consistentemente a partir do c√≥digo fonte. |

-----

## üß† Metodologia e Produtividade

Este projeto foi desenvolvido utilizando uma abordagem de **Engenharia Aumentada por IA (AI-Augmented Engineering)**, onde o modelo **Gemini (Google)** atuou como um *pair programmer* arquitetural. Esta metodologia visa demonstrar profici√™ncia em ferramentas de IA para **ganho de produtividade**, mantendo total controle e entendimento das decis√µes arquiteturais tomadas.
