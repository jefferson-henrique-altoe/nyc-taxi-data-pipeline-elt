# üöï Desafio T√©cnico: Engenharia de Dados NYC Taxi Trips

Este reposit√≥rio cont√©m uma solu√ß√£o completa de Engenharia de Dados **Serverless** para ingest√£o, processamento e **an√°lise pr√©-agregada** dos dados de viagens de t√°xi de Nova York.

A arquitetura utiliza uma stack **Cloud-Native (AWS)** com orquestra√ß√£o centralizada no **AWS Step Functions**, garantindo um fluxo ELT robusto: **Landing** $\rightarrow$ **Consumer** $\rightarrow$ \*\*Reporting$.

-----

## üöÄ Stack Tecnol√≥gica e Arquitetura Final

| Etapa do Pipeline | Tecnologia/Servi√ßo | Finalidade no Projeto |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | **AWS Step Functions** | **Controlador Serverless.** Gerencia o *workflow* e utiliza o estado `Map` para paralelizar o processamento por m√™s e tipo de viagem. |
| **Infraestrutura como C√≥digo (IaC)** | **Terraform** | Provisionamento seguro e automatizado de **todos** os recursos (S3, Glue Jobs, Lambda, Step Functions, IAM Roles e Tabelas do Athena). |
| **Data Lake e Armazenamento** | **Amazon S3** | Armazenamento persistente nas camadas: `landing`, `consumer` (Delta/Parquet) e `analytics/reporting` (Parquet pr√©-agregado). |
| **Ingest√£o (EL)** | **AWS Lambda (Python)** | Baixa os arquivos e faz o upload para a **Landing Zone**, particionado por *timestamp* de ingest√£o. |
| **Processing (T - Camada Consumer)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** L√™ a √∫ltima vers√£o dos dados, aplica Data Quality (DQ) e salva na **Camada Consumer** (Delta Lake). |
| **Reporting (T - Camada Reporting)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** L√™ a Camada Consumer, executa as agrega√ß√µes **Q1 e Q2** e salva os relat√≥rios na **Camada Reporting** (pronto para consumo). |
| **Cat√°logo de Dados** | **AWS Glue Data Catalog** | Registro do *schema* de todas as tabelas (`trips_consumer`, `q1_monthly_revenue`, `q2_hourly_passengers`) para acesso via SQL. |
| **Consumo e An√°lise Ad-Hoc** | **Amazon Athena / PyAthena** | Permite consultas SQL diretas sobre os relat√≥rios pr√©-agregados, garantindo baixo custo e alta performance. |

-----

## üí∞ FinOps: Gest√£o de Custos Serverless

A arquitetura **Serverless** (Lambda, Glue, Step Functions) oferece um excelente balan√ßo entre performance e custo, seguindo o princ√≠pio **pay-per-use** (pague apenas pelo que usar), o que √© ideal para *pipelines* de dados intermitentes como este.

### Principais Drivers de Custo

  * **AWS Glue (DPUs):** √â o componente de maior custo potencial. O pre√ßo √© baseado em **DPUs (Data Processing Units) por hora**. Para mitigar isso:
      * Usamos o Glue 3.0 (mais r√°pido e eficiente).
      * Os Jobs s√£o otimizados para tempo de execu√ß√£o m√≠nimo (leitura de Delta e escritas em Parquet eficientes).
  * **Amazon S3 (Armazenamento):** O custo principal aqui √© o armazenamento dos dados nas tr√™s camadas (Landing, Consumer, Reporting). O custo por GB √© baixo, mas √© cont√≠nuo.
  * **AWS Step Functions:** O custo √© baseado no n√∫mero de **transi√ß√µes de estado** (State Transitions), que √© muito baixo, mas escal√°vel.

### Boas Pr√°ticas FinOps

Para garantir a efici√™ncia de custos fora do Free Tier, a melhor pr√°tica FinOps neste projeto √©:

  * **Destrui√ß√£o Imediata:** Ap√≥s o teste e valida√ß√£o, utilize o comando `make destroy` para desprovisionar toda a infraestrutura e evitar cobran√ßas recorrentes de recursos como Volumes EBS (anexados ao Glue) ou S3, mantendo apenas o c√≥digo localmente.

-----

## üéØ Objetivo e Transforma√ß√£o

O objetivo √© processar os dados de viagens de t√°xi de **Janeiro a Maio de 2023** e disponibilizar, na **Camada Reporting**, as seguintes an√°lises prontas:

1.  **Q1:** M√©dia de valor total (`total_amount`) por m√™s.
2.  **Q2:** M√©dia de passageiros por cada hora do dia, agrupado por tipo de viagem.

-----

## 1\. ‚öôÔ∏è Fase 1: Provisionamento e Execu√ß√£o do ELT

### 1.1. Pr√©-requisitos e Setup Local

1.  **Python 3.x**, **`pip`**, **`make`** e **Terraform CLI**.
2.  **AWS CLI** configurado (via `aws configure`) com credenciais que possuam permiss√µes de acesso.

### 1.2. Provisionamento da Infraestrutura (IaC)

Utilize o **`Makefile`** para automatizar o *build* do pacote Lambda e a execu√ß√£o do Terraform. O `make deploy` √© o comando principal que encapsula ambos.

| Comando | A√ß√£o Executada | Observa√ß√µes |
| :--- | :--- | :--- |
| **`make deploy`** | **Execu√ß√£o Completa.** Prepara o pacote Python da Lambda, inicializa o Terraform e executa o `terraform apply --auto-approve`. | Comando principal de *setup* e deployment. |
| **`make destroy`** | **Destr√≥i toda a infraestrutura da AWS (CUIDADO: Apaga dados).** | |
| **`make clean`** | Remove artefatos locais (`lambda_deployment_package`, `.terraform`, `.tfstate`). | √ötil para limpeza e garantia de um *build* limpo. |

-----

## 2\. üèÉ‚Äç‚ôÇÔ∏è Fase 2: Execu√ß√£o Din√¢mica e Paralela do Pipeline

O Step Function agora suporta um *payload* din√¢mico para rodar o Processamento e Reporting em paralelo para m√∫ltiplos meses e tipos de t√°xi, utilizando o estado `Map`.

### 2.1. Estrutura de Entrada (Payload)

O *payload* define quais dados devem ser processados e alimenta o estado `Map` para otimizar as execu√ß√µes do AWS Glue.

**Payload de Exemplo (Processamento em Lote):**

```json
{
  "datalakeBucket": "nyc-taxi-data-lake-jha-case-ifood",
  "year": "2023",
  "months": [
    "02",
    "03",
    "04",
    "05"
  ],
  "trip_types": [
    "yellow",
    "green"
  ]
}
```

| Chave | Descri√ß√£o | Uso |
| :--- | :--- | :--- |
| **`months`** | Lista de meses ("MM") a serem processados. | Utilizado no estado `Map` para criar execu√ß√µes paralelas de ELT. |
| **`trip_types`** | Tipos de t√°xis a serem processados. | Utilizado no estado `Map` para criar execu√ß√µes paralelas por tipo. |

### 2.2. Execu√ß√£o Customizada

Obtenha o ARN da State Machine na sa√≠da do Terraform: `nyc-taxi-elt-pipeline`.

```bash
# Exemplo de Payload: Processar Mar√ßo e Abril de 2024 (Apenas Green)
INPUT='{
    "datalakeBucket": "nyc-taxi-data-lake-jha-case-ifood",
    "year": "2024", 
    "months": ["03", "04"], 
    "trip_types": ["green"]
}'

aws stepfunctions start-execution \
    --state-machine-arn "ARN_DA_SUA_STATE_MACHINE" \
    --name "Run-Custom-Batch-$(date +%Y%m%d%H%M%S)" \
    --input "$INPUT"
```

**Verifica√ß√£o de Falhas:** O Step Function est√° configurado para **falhar imediatamente** se qualquer Job Glue ou a Lambda retornar um erro, garantindo a integridade do *workflow*.

-----

## 3\. üß© Fase 3: Reporting e Disponibiliza√ß√£o (Q1 e Q2)

Ap√≥s a conclus√£o do Job de Reporting, os relat√≥rios agregados est√£o dispon√≠veis na **Camada Reporting** do S3 e catalogados pelo Glue Data Catalog.

### Tabelas do Glue Catalog para Consulta Final

| Tabela | An√°lise | Caminho no S3 |
| :--- | :--- | :--- |
| `q1_monthly_revenue` | M√©dia Mensal de Receita | `s3://<SEU_BUCKET>/analytics/reporting/q1_monthly_revenue/` |
| `q2_hourly_passengers` | M√©dia Hor√°ria de Passageiros | `s3://<SEU_BUCKET>/analytics/reporting/q2_hourly_passengers/` |

-----

## 4\. üîç Fase 4: An√°lise e Consumo Final de Dados

O consumo dos relat√≥rios pr√©-agregados pode ser feito via Amazon Athena.

### 4.1. Acesso Direto via Amazon Athena (SQL)

No Console do **Amazon Athena**, selecione o banco de dados `nyc_taxi_db` e execute:

```sql
SELECT 
    report_month, 
    ROUND(avg_total_amount, 2) AS avg_revenue
FROM 
    "nyc_taxi_db"."q1_monthly_revenue"
ORDER BY 
    report_month;
```

### 4.2. Acesso Program√°tico Local (Script PyAthena)

Instale as depend√™ncias locais e execute o script `analysis/analytics_job.py`:

```bash
# Instala o driver do Athena e o Pandas
pip3 install pyathena[pandas]

# O script ir√° consultar o Athena e imprimir os resultados
python analysis/analytics_job.py
```

-----

## 5\. üí° Melhorias e Pr√≥ximos Passos (To-Do)

A solu√ß√£o atual √© funcional, mas esta lista de melhorias visa aumentar a **resili√™ncia**, a **performance** e a **governan√ßa** do pipeline, abordando li√ß√µes aprendidas nos testes.

### 5.1. Resolu√ß√£o de Inconsist√™ncia de Schema (M√™s 1)

Durante a execu√ß√£o de testes, os dados do M√™s 1 (Janeiro) falharam no Job de Processing, enquanto os meses subsequentes (2 a 5) foram processados com sucesso.

  * **Problema:** Isto sugere uma **inconsist√™ncia de tipo de dado (schema drift)** ou valor at√≠pico no arquivo de Janeiro, que n√£o foi tratado pelo esquema flex√≠vel do Spark.
  * **A√ß√£o (To-Do):** Refinar o Job de Processing para garantir a **resili√™ncia de schema** atrav√©s de:
      * Implementar um *schema* estrito para colunas cr√≠ticas.
      * Adotar o tratamento de erros do Spark (`badRecordsPath`) ou mover explicitamente os registros inv√°lidos para uma **Dead Letter Queue (DLQ)**, isolando o problema e permitindo o processamento cont√≠nuo dos dados v√°lidos.

### 5.2. Otimiza√ß√£o de Governan√ßa de Dados

  * **Crawler Autom√°tico:** Criar e integrar um AWS Glue Crawler ao final do Step Functions. Este Crawler deve ser acionado ap√≥s a conclus√£o do Job de Reporting para garantir que o *schema* das tabelas `q1_monthly_revenue` e `q2_hourly_passengers` esteja sempre atualizado no Glue Catalog.

### 5.3. Otimiza√ß√£o de Custos e Performance

  * **Filtro na Leitura do Delta:** Otimizar o Job de Reporting para usar **filtros de *pushdown*** ao ler a Camada Consumer, mesmo que a arquitetura Delta ajude. Isso minimiza a quantidade de dados lidos antes do processamento.
  * **Glue Worker Type:** Avaliar a migra√ß√£o do Glue Job para *Worker Type* como `G.1X` ou `G.2X` para tarefas de *reporting* mais pesadas, buscando um *sweet spot* entre o aumento de custo e o tempo de execu√ß√£o (tempo √© dinheiro).

-----

## üß† Metodologia e Produtividade

Este projeto foi desenvolvido utilizando uma abordagem de **Engenharia Aumentada por IA (AI-Augmented Engineering)**. O modelo de linguagem **Gemini (Google)** foi utilizado como um *pair programmer* arquitetural para:

1.  **Orquestra√ß√£o Serverless:** Implementar o **AWS Step Functions** como orquestrador central, elevando o pipeline a um n√≠vel profissional com monitoramento e controle de fluxo.
2.  **Idempot√™ncia e Versionamento:** Adotar a estrat√©gia de *timestamp* na Landing Zone para garantir a imutabilidade do dado *raw* e a leitura da √∫ltima vers√£o pelo processamento ETL.
3.  **Otimiza√ß√£o de Custos e Seguran√ßa:** Orienta√ß√£o na configura√ß√£o eficiente dos recursos (Lambda, Glue Workers) e uso de IAM Roles, mantendo o custo AWS baixo e a seguran√ßa em alta.

Esta metodologia visa demonstrar profici√™ncia em ferramentas de IA para **ganho de produtividade**, mantendo total controle e entendimento das decis√µes arquiteturais tomadas.
