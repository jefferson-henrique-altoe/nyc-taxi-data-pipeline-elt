# üöï Desafio T√©cnico: Engenharia de Dados NYC Taxi Trips

Este reposit√≥rio cont√©m uma solu√ß√£o completa de Engenharia de Dados **Serverless** para ingest√£o, processamento e **an√°lise pr√©-agregada** dos dados de viagens de t√°xi de Nova York.

A arquitetura utiliza uma stack **Cloud-Native (AWS)** com orquestra√ß√£o centralizada no **AWS Step Functions**, garantindo um fluxo ELT robusto: **Landing** $\rightarrow$ **Consumer** $\rightarrow$ **Reporting**.

---

## üöÄ Stack Tecnol√≥gica e Arquitetura Final

| Etapa do Pipeline | Tecnologia/Servi√ßo | Finalidade no Projeto |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | **AWS Step Functions** | **Controlador Serverless.** Garante o *workflow* sequencial de tr√™s passos: Ingest√£o $\rightarrow$ Processamento $\rightarrow$ Reporting. |
| **Infraestrutura como C√≥digo (IaC)** | **Terraform** | Provisionamento seguro e automatizado de **todos** os recursos (S3, Glue Jobs, Lambda, Step Functions, IAM Roles e Tabelas do Athena). |
| **Data Lake e Armazenamento** | **Amazon S3** | Armazenamento persistente nas camadas: `landing`, `consumer` (Delta/Parquet) e `analytics/reporting` (Parquet pr√©-agregado). |
| **Ingest√£o (EL)** | **AWS Lambda (Python)** | Baixa os arquivos e faz o upload para a **Landing Zone**, particionado por *timestamp* de ingest√£o. |
| **Processamento (T - Camada Consumer)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** L√™ a √∫ltima vers√£o dos dados, aplica Data Quality (DQ) e salva na **Camada Consumer** (Delta Lake). |
| **Reporting (T - Camada Reporting)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** L√™ a Camada Consumer, executa as agrega√ß√µes **Q1 e Q2** e salva os relat√≥rios na **Camada Reporting** (pronto para consumo). |
| **Cat√°logo de Dados** | **AWS Glue Data Catalog** | Registro do *schema* de todas as tabelas (`trips_consumer`, `q1_monthly_revenue`, `q2_hourly_passengers`) para acesso via SQL. |
| **Consumo e An√°lise Ad-Hoc** | **Amazon Athena / PyAthena** | Permite consultas SQL diretas sobre os relat√≥rios pr√©-agregados, garantindo baixo custo e alta performance. |

---

## üéØ Objetivo e Transforma√ß√£o

O objetivo √© processar os dados de viagens de t√°xi de **Janeiro a Maio de 2023** e disponibilizar, na **Camada Reporting**, as seguintes an√°lises prontas:

1.  **Q1:** M√©dia de valor total (`total_amount`) por m√™s.
2.  **Q2:** M√©dia de passageiros por cada hora do dia, agrupado por tipo de viagem.

---

## 1\. ‚öôÔ∏è Fase 1: Provisionamento e Execu√ß√£o do ELT

### 1.1. Pr√©-requisitos e Setup Local

1.  **Python 3.x**, **`pip`** e **`make`**.
2.  **Terraform CLI**.
3.  **AWS CLI** configurado (via `aws configure`) com credenciais que possuam permiss√µes para todos os servi√ßos necess√°rios (S3, Glue, Lambda, Step Functions, IAM e Athena).

### 1.2. Provisionamento da Infraestrutura com Terraform (IaC)

Todos os recursos de S3, IAM, Glue Jobs (Processamento e Reporting) e o Step Function s√£o provisionados via `terraform apply`, orquestrado pelo `Makefile`.

| Comando | A√ß√£o Executada |
| :--- | :--- |
| **`make deploy`** | Prepara o pacote Lambda, faz upload dos scripts Glue e executa `terraform apply --auto-approve`. |
| **`make destroy`** | **Destr√≥i toda a infraestrutura da AWS (CUIDADO: Apaga dados).** |

### 1.3. Execu√ß√£o da Orquestra√ß√£o (Pipeline ELT Completo)

O Step Function gerencia o fluxo de tr√™s est√°gios. O ARN da State Machine pode ser obtido na sa√≠da do Terraform: `nyc-taxi-elt-pipeline`.

#### 1.3.1. Execu√ß√£o Padr√£o (Valores Iniciais do Desafio)

A invoca√ß√£o sem um *payload* espec√≠fico usar√° os valores *default* (Janeiro a Maio de 2023).

```bash
# Substitua pelo seu ARN da State Machine
STATE_MACHINE_ARN="ARN_DA_SUA_STATE_MACHINE" 

# Invoca o Step Function. Payload vazio ({}) usa os valores default
aws stepfunctions start-execution \
    --state-machine-arn $STATE_MACHINE_ARN \
    --name "Run-$(date +%Y%m%d%H%M%S)" \
    --input '{}'
````

#### 1.3.2. Execu√ß√£o Customizada (Exemplo: Julho de 2024, Apenas Yellow)

Para ingerir dados de um per√≠odo ou tipo de viagem diferente, passe um objeto JSON no campo `--input`:

```bash
# Payload para customizar a execu√ß√£o: ano 2024, m√™s 07, apenas yellow
INPUT='{"year": "2024", "months": ["07"], "trip_types": ["yellow"]}'

aws stepfunctions start-execution \
    --state-machine-arn $STATE_MACHINE_ARN \
    --name "Run-July2024-$(date +%Y%m%d%H%M%S)" \
    --input "$INPUT"
```

**Verifica√ß√£o:** Acompanhe o gr√°fico de execu√ß√£o no Console do AWS Step Functions para garantir que o fluxo de **tr√™s tarefas** (`Lambda` $\rightarrow$ `Glue Processing` $\rightarrow$ `Glue Reporting`) seja conclu√≠do com sucesso.

-----

## 2\. üß© Fase 2: Reporting e Disponibiliza√ß√£o (Q1 e Q2)

Ap√≥s a conclus√£o do Job de Reporting, os relat√≥rios agregados est√£o dispon√≠veis na **Camada Reporting** do S3 e catalogados pelo Glue Data Catalog.

### Tabelas do Glue Catalog para Consulta Final

| Tabela | An√°lise | Caminho no S3 |
| :--- | :--- | :--- |
| `q1_monthly_revenue` | M√©dia Mensal de Receita | `s3://<SEU_BUCKET>/analytics/reporting/q1_monthly_revenue/` |
| `q2_hourly_passengers` | M√©dia Hor√°ria de Passageiros | `s3://<SEU_BUCKET>/analytics/reporting/q2_hourly_passengers/` |

-----

## 3\. üîç Fase 3: An√°lise e Consumo Final de Dados

O consumo dos relat√≥rios pr√©-agregados pode ser feito de duas maneiras, ambas acessando as tabelas catalogadas via Amazon Athena.

### 3.1. Acesso Direto via Amazon Athena (SQL)

Este √© o m√©todo mais r√°pido para valida√ß√£o manual no console AWS:

1.  Acesse o Console do **Amazon Athena** e selecione o banco de dados `nyc_taxi_db`.
2.  Execute a consulta na tabela de relat√≥rio, por exemplo:

<!-- end list -->

```sql
SELECT 
    report_month, 
    ROUND(avg_total_amount, 2) AS avg_revenue
FROM 
    "nyc_taxi_db"."q1_monthly_revenue"
ORDER BY 
    report_month;
```

### 3.2. Acesso Program√°tico Local (Script PyAthena)

Para integrar a an√°lise em um ambiente Python local (como o script `analytics_job.py`):

#### A. Instala√ß√£o de Depend√™ncias Locais

√â necess√°rio instalar as bibliotecas que far√£o a comunica√ß√£o com o Athena e processar√£o o resultado em um DataFrame.

```bash
# Instala o driver do Athena e o Pandas
pip install pyathena[pandas]
```

#### B. Execu√ß√£o do Script

Certifique-se de que o **`analytics_job.py`** esteja configurado com o nome do seu bucket S3 e que suas credenciais AWS estejam ativas na m√°quina.

```bash
# O script ir√° consultar o Athena e imprimir os resultados
python analysis/analytics_job.py
```

O sucesso dessas consultas confirma que todo o pipeline ELT est√° operacional e que os relat√≥rios de neg√≥cio est√£o prontos para o consumo.

-----

## üß† Metodologia e Produtividade

Este projeto foi desenvolvido utilizando uma abordagem de **Engenharia Aumentada por IA (AI-Augmented Engineering)**. O modelo de linguagem **Gemini (Google)** foi utilizado como um *pair programmer* arquitetural para:

1.  **Orquestra√ß√£o Serverless:** Implementar o **AWS Step Functions** como orquestrador central, elevando o pipeline a um n√≠vel profissional com monitoramento e controle de fluxo.
2.  **Idempot√™ncia e Versionamento:** Adotar a estrat√©gia de *timestamp* na Landing Zone para garantir a imutabilidade do dado *raw* e a leitura da √∫ltima vers√£o pelo processamento ETL.
3.  **Otimiza√ß√£o de Custos e Seguran√ßa:** Orienta√ß√£o na configura√ß√£o eficiente dos recursos (Lambda, Glue Workers) e uso de IAM Roles, mantendo o custo AWS baixo e a seguran√ßa em alta.

Esta metodologia visa demonstrar profici√™ncia em ferramentas de IA para **ganho de produtividade**, mantendo total controle e entendimento das decis√µes arquiteturais tomadas.
