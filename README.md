# üöï Desafio T√©cnico: Engenharia de Dados NYC Taxi Trips

Este reposit√≥rio cont√©m uma solu√ß√£o completa de Engenharia de Dados **Serverless** para ingest√£o, processamento e **an√°lise pr√©-agregada** dos dados de viagens de t√°xi de Nova York.

A arquitetura utiliza uma stack **Cloud-Native (AWS)** com orquestra√ß√£o centralizada no **AWS Step Functions**, garantindo um fluxo ELT robusto: **Landing** $\rightarrow$ **Consumer** $\rightarrow$ **Reporting**.

---

## üöÄ Stack Tecnol√≥gica e Arquitetura Final

| Etapa do Pipeline | Tecnologia/Servi√ßo | Finalidade no Projeto |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | **AWS Step Functions** | **Controlador Serverless.** Garante o *workflow* sequencial de tr√™s passos: Ingest√£o $\rightarrow$ Processamento $\rightarrow$ Reporting. |
| **Infraestrutura como C√≥digo (IaC)** | **Terraform** | Provisionamento seguro e automatizado de **todos** os recursos (S3, Glue Jobs, Lambda, Step Functions, IAM Roles e Tabelas do Athena). |
| **Data Lake e Armazenamento** | **Amazon S3** | Armazenamento persistente nas camadas: `landing`, `consumer` (Delta/Parquet) e `analytics/reporting` (Parquet pr√©-agregado). |
| **Ingest√£o (EL)** | **AWS Lambda (Python)** | Baixa os arquivos e faz o upload para a **Landing Zone**, particionado por *timestamp* de ingest√£o. |
| **Processing (T - Camada Consumer)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** L√™ a √∫ltima vers√£o dos dados, aplica Data Quality (DQ) e salva na **Camada Consumer** (Delta Lake). |
| **Reporting (T - Camada Reporting)** | **AWS Glue Job (PySpark)** | **Motor ETL Serverless.** L√™ a Camada Consumer, executa as agrega√ß√µes **Q1 e Q2** e salva os relat√≥rios na **Camada Reporting** (pronto para consumo). |
| **Cat√°logo de Dados** | **AWS Glue Data Catalog** | Registro do *schema* de todas as tabelas (`trips_consumer`, `q1_monthly_revenue`, `q2_hourly_passengers`) para acesso via SQL. |
| **Consumo e An√°lise Ad-Hoc** | **Amazon Athena / PyAthena** | Permite consultas SQL diretas sobre os relat√≥rios pr√©-agregados, garantindo baixo custo e alta performance. |

---

## üí∞ FinOps: Gest√£o de Custos Serverless

A arquitetura **Serverless** (Lambda, Glue, Step Functions) oferece um excelente balan√ßo entre performance e custo, seguindo o princ√≠pio **pay-per-use** (pague apenas pelo que usar), o que √© ideal para *pipelines* de dados intermitentes como este.

### Principais Drivers de Custo

* **AWS Glue (DPUs):** √â o componente de maior custo potencial. O pre√ßo √© baseado em **DPUs (Data Processing Units) por hora**. Para mitigar isso:
    * Usamos o Glue 3.0 (mais r√°pido e eficiente).
    * Os Jobs s√£o otimizados para tempo de execu√ß√£o m√≠nimo (leitura de Delta e escritas em Parquet eficientes).
* **Amazon S3 (Armazenamento):** O custo principal aqui √© o armazenamento dos dados nas tr√™s camadas (Landing, Consumer, Reporting). O custo por GB √© baixo, mas √© cont√≠nuo.
* **AWS Step Functions:** O custo √© baseado no n√∫mero de **transi√ß√µes de estado** (State Transitions), que √© muito baixo, mas escal√°vel.

### O Papel do Free Tier

A **Camada Gratuita da AWS** cobre integralmente ou parcialmente o uso de v√°rios servi√ßos (Lambda, S3, Step Functions) por um ano, tornando este projeto financeiramente vi√°vel para testes iniciais e aprendizado.

### Boas Pr√°ticas FinOps

Para garantir a efici√™ncia de custos fora do Free Tier, a melhor pr√°tica FinOps neste projeto √©:

* **Destrui√ß√£o Imediata:** Ap√≥s o teste e valida√ß√£o, utilize o comando `make destroy` para desprovisionar toda a infraestrutura e evitar cobran√ßas recorrentes de recursos como Volumes EBS (anexados ao Glue) ou S3, mantendo apenas o c√≥digo localmente.

---

## üéØ Objetivo e Transforma√ß√£o

O objetivo √© processar os dados de viagens de t√°xi de **Janeiro a Maio de 2023** e disponibilizar, na **Camada Reporting**, as seguintes an√°lises prontas:

1.  **Q1:** M√©dia de valor total (`total_amount`) por m√™s.
2.  **Q2:** M√©dia de passageiros por cada hora do dia, agrupado por tipo de viagem.

---

## 1\. ‚öôÔ∏è Fase 1: Provisionamento e Execu√ß√£o do ELT

### 1.1. Pr√©-requisitos e Setup Local

1.  **Python 3.x**, **`pip`**, **`make`** e **Terraform CLI**.
2.  **AWS CLI** configurado (via `aws configure`) com credenciais que possuam permiss√µes de acesso.

### 1.2. Provisionamento da Infraestrutura (IaC)

Utilize o **`Makefile`** para automatizar o *build* do pacote Lambda e a execu√ß√£o do Terraform. O `make deploy` √© o comando principal que encapsula ambos.

| Comando | A√ß√£o Executada | Observa√ß√µes |
| :--- | :--- | :--- |
| **`make deploy`** | **Execu√ß√£o Completa.** Prepara o pacote Python da Lambda, inicializa o Terraform e executa o `terraform apply --auto-approve`. | Comando principal de *setup* e deployment. |
| **`make destroy`** | **Destr√≥i toda a infraestrutura da AWS (CUIDADO: Apaga dados).** | |
| **`make clean`** | Remove artefatos locais (`lambda_deployment_package`, `.terraform`, `.tfstate`). | √ötil para limpeza e garantia de um *build* limpo. |

### 1.3. Execu√ß√£o da Orquestra√ß√£o (Pipeline ELT Completo)

O Step Function gerencia o fluxo de tr√™s est√°gios. Obtenha o ARN da State Machine na sa√≠da do Terraform: `nyc-taxi-elt-pipeline`.

#### 1.3.1. Execu√ß√£o Padr√£o (Jan-Mai 2023)

```bash
# Substitua pelo seu ARN da State Machine
STATE_MACHINE_ARN="ARN_DA_SUA_STATE_MACHINE" 

# Invoca o Step Function com payload vazio ({}) para usar os valores default
aws stepfunctions start-execution \
    --state-machine-arn $STATE_MACHINE_ARN \
    --name "Run-$(date +%Y%m%d%H%M%S)" \
    --input '{}'
````

# #### 1.3.2. Execu√ß√£o Customizada (Exemplo: Julho de 2024, Apenas Yellow)

# Passe um objeto JSON para customizar o per√≠odo de ingest√£o:

# ```bash
# # Payload para customizar a execu√ß√£o: ano 2024, m√™s 07, apenas yellow
# INPUT='{"year": "2024", "months": ["07"], "trip_types": ["yellow"]}'

# aws stepfunctions start-execution \
#     --state-machine-arn $STATE_MACHINE_ARN \
#     --name "Run-July2024-$(date +%Y%m%d%H%M%S)" \
#     --input "$INPUT"
# ```

# **Verifica√ß√£o de Falhas:** O Step Function est√° configurado para **falhar imediatamente** se qualquer um dos Glue Jobs (`Processing` ou `Reporting`) ou a Lambda retornar um erro, garantindo que a execu√ß√£o n√£o fique travada.

#### 1.3.2. Execu√ß√£o Customizada (Customizando o Per√≠odo e Tipos de Viagem)

O Step Function aceita um objeto JSON como input para **customizar a janela de tempo** e os **tipos de t√°xi** a serem processados. Se o input for `{}`, o pipeline usa os valores padr√£o definidos abaixo:

| Par√¢metro | Tipo | Descri√ß√£o | Valores Padr√£o (se input for `{}`) |
| :--- | :--- | :--- | :--- |
| **`year`** | `String` | O ano de refer√™ncia dos dados (e.g., `"2023"`, `"2024"`). | `"2023"` |
| **`months`** | `Array<String>` | Lista de meses a serem processados, no formato de dois d√≠gitos (e.g., `["01", "02", "03"]`). | `["01", "02", "03", "04", "05"]` |
| **`trip_types`** | `Array<String>` | Lista de tipos de t√°xi a serem inclu√≠dos. Tipos v√°lidos: `yellow`, `green`, `fhv`. | `["yellow", "green", "fhv"]` |

**Exemplo de Execu√ß√£o Customizada (Julho de 2024, Apenas Yellow e Green):**

Passe o objeto JSON abaixo no argumento `--input`:

```bash
# Payload para customizar a execu√ß√£o: ano 2024, m√™s 07, apenas yellow e green
INPUT='{
    "year": "2024", 
    "months": ["07"], 
    "trip_types": ["yellow", "green"]
}'

aws stepfunctions start-execution \
    --state-machine-arn $STATE_MACHINE_ARN \
    --name "Run-July2024-YellowGreen-$(date +%Y%m%d%H%M%S)" \
    --input "$INPUT"

-----

## 2\. üß© Fase 2: Reporting e Disponibiliza√ß√£o (Q1 e Q2)

Ap√≥s a conclus√£o do Job de Reporting, os relat√≥rios agregados est√£o dispon√≠veis na **Camada Reporting** do S3 e catalogados pelo Glue Data Catalog.

### Tabelas do Glue Catalog para Consulta Final

| Tabela | An√°lise | Caminho no S3 |
| :--- | :--- | :--- |
| `q1_monthly_revenue` | M√©dia Mensal de Receita | `s3://<SEU_BUCKET>/analytics/reporting/q1_monthly_revenue/` |
| `q2_hourly_passengers` | M√©dia Hor√°ria de Passageiros | `s3://<SEU_BUCKET>/analytics/reporting/q2_hourly_passengers/` |

-----

## 3\. üîç Fase 3: An√°lise e Consumo Final de Dados

O consumo dos relat√≥rios pr√©-agregados pode ser feito via Amazon Athena.

### 3.1. Acesso Direto via Amazon Athena (SQL)

No Console do **Amazon Athena**, selecione o banco de dados `nyc_taxi_db` e execute:

```sql
SELECT 
    report_month, 
    ROUND(avg_total_amount, 2) AS avg_revenue
FROM 
    "nyc_taxi_db"."q1_monthly_revenue"
ORDER BY 
    report_month;
```

### 3.2. Acesso Program√°tico Local (Script PyAthena)

Instale as depend√™ncias locais e execute o script `analysis/analytics_job.py`:

```bash
# Instala o driver do Athena e o Pandas
pip3 install pyathena[pandas]

# O script ir√° consultar o Athena e imprimir os resultados
python analysis/analytics_job.py
```

-----

## üß† Metodologia e Produtividade

Este projeto foi desenvolvido utilizando uma abordagem de **Engenharia Aumentada por IA (AI-Augmented Engineering)**. O modelo de linguagem **Gemini (Google)** foi utilizado como um *pair programmer* arquitetural para:

1.  **Orquestra√ß√£o Serverless:** Implementar o **AWS Step Functions** como orquestrador central, elevando o pipeline a um n√≠vel profissional com monitoramento e controle de fluxo.
2.  **Idempot√™ncia e Versionamento:** Adotar a estrat√©gia de *timestamp* na Landing Zone para garantir a imutabilidade do dado *raw* e a leitura da √∫ltima vers√£o pelo processamento ETL.
3.  **Otimiza√ß√£o de Custos e Seguran√ßa:** Orienta√ß√£o na configura√ß√£o eficiente dos recursos (Lambda, Glue Workers) e uso de IAM Roles, mantendo o custo AWS baixo e a seguran√ßa em alta.

Esta metodologia visa demonstrar profici√™ncia em ferramentas de IA para **ganho de produtividade**, mantendo total controle e entendimento das decis√µes arquiteturais tomadas.
